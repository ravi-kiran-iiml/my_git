{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CC Fraud detection_kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONXkt/fCEaSfFZxcKcsocX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-kiran-iiml/my_git/blob/master/CC_Fraud_detection_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zvbROdfpi29",
        "colab_type": "text"
      },
      "source": [
        "Brief about this dataset from Kaggle.com : \n",
        "\n",
        "Context\n",
        "\n",
        "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
        "\n",
        "Content\n",
        "\n",
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
        "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
        "\n",
        "Inspiration\n",
        "\n",
        "Identify fraudulent credit card transactions.\n",
        "\n",
        "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n",
        "\n",
        "Acknowledgements\n",
        "\n",
        "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection.\n",
        "More details on current and past projects on related topics are available on https://www.researchgate.net/project/Fraud-detection-5 and the page of the DefeatFraud project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7I1hxqVzp6H",
        "colab_type": "text"
      },
      "source": [
        "First step: We import the dataset from the respective folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unEvfnvcldZm",
        "colab_type": "code",
        "outputId": "21227eaa-0a46-4a42-d352-c3c048781f8f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66cf69ce-c99a-4b8f-98f2-a889c64dffab\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-66cf69ce-c99a-4b8f-98f2-a889c64dffab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving creditcard_sample.csv to creditcard_sample.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBuzPwBrzyYs",
        "colab_type": "text"
      },
      "source": [
        "Next we create the dataframe using pandas.read_csv function\n",
        "\n",
        "\n",
        "Dataframe.head() gives us a picture of the first few rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLfIjqyiq5zA",
        "colab_type": "code",
        "outputId": "aa876676-7370-4d6c-ecc5-3c583dfcd58b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "dataframe = pd.read_csv(io.BytesIO(uploaded['creditcard_sample.csv']))\n",
        "dataframe.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.425966</td>\n",
              "      <td>0.960523</td>\n",
              "      <td>1.141109</td>\n",
              "      <td>-0.168252</td>\n",
              "      <td>0.420987</td>\n",
              "      <td>-0.029728</td>\n",
              "      <td>0.476201</td>\n",
              "      <td>0.260314</td>\n",
              "      <td>-0.568671</td>\n",
              "      <td>-0.371407</td>\n",
              "      <td>1.341262</td>\n",
              "      <td>0.359894</td>\n",
              "      <td>-0.358091</td>\n",
              "      <td>-0.137134</td>\n",
              "      <td>0.517617</td>\n",
              "      <td>0.401726</td>\n",
              "      <td>-0.058133</td>\n",
              "      <td>0.068653</td>\n",
              "      <td>-0.033194</td>\n",
              "      <td>0.084968</td>\n",
              "      <td>-0.208254</td>\n",
              "      <td>-0.559825</td>\n",
              "      <td>-0.026398</td>\n",
              "      <td>-0.371427</td>\n",
              "      <td>-0.232794</td>\n",
              "      <td>0.105915</td>\n",
              "      <td>0.253844</td>\n",
              "      <td>0.081080</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>1.229658</td>\n",
              "      <td>0.141004</td>\n",
              "      <td>0.045371</td>\n",
              "      <td>1.202613</td>\n",
              "      <td>0.191881</td>\n",
              "      <td>0.272708</td>\n",
              "      <td>-0.005159</td>\n",
              "      <td>0.081213</td>\n",
              "      <td>0.464960</td>\n",
              "      <td>-0.099254</td>\n",
              "      <td>-1.416907</td>\n",
              "      <td>-0.153826</td>\n",
              "      <td>-0.751063</td>\n",
              "      <td>0.167372</td>\n",
              "      <td>0.050144</td>\n",
              "      <td>-0.443587</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>-0.611987</td>\n",
              "      <td>-0.045575</td>\n",
              "      <td>-0.219633</td>\n",
              "      <td>-0.167716</td>\n",
              "      <td>-0.270710</td>\n",
              "      <td>-0.154104</td>\n",
              "      <td>-0.780055</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>-0.257237</td>\n",
              "      <td>0.034507</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>1.249376</td>\n",
              "      <td>-0.619468</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>1.757964</td>\n",
              "      <td>-1.323865</td>\n",
              "      <td>0.686133</td>\n",
              "      <td>-0.076127</td>\n",
              "      <td>-1.222127</td>\n",
              "      <td>-0.358222</td>\n",
              "      <td>0.324505</td>\n",
              "      <td>-0.156742</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>40.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>-0.894286</td>\n",
              "      <td>0.286157</td>\n",
              "      <td>-0.113192</td>\n",
              "      <td>-0.271526</td>\n",
              "      <td>2.669599</td>\n",
              "      <td>3.721818</td>\n",
              "      <td>0.370145</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>-0.392048</td>\n",
              "      <td>-0.410430</td>\n",
              "      <td>-0.705117</td>\n",
              "      <td>-0.110452</td>\n",
              "      <td>-0.286254</td>\n",
              "      <td>0.074355</td>\n",
              "      <td>-0.328783</td>\n",
              "      <td>-0.210077</td>\n",
              "      <td>-0.499768</td>\n",
              "      <td>0.118765</td>\n",
              "      <td>0.570328</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>-0.073425</td>\n",
              "      <td>-0.268092</td>\n",
              "      <td>-0.204233</td>\n",
              "      <td>1.011592</td>\n",
              "      <td>0.373205</td>\n",
              "      <td>-0.384157</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.142404</td>\n",
              "      <td>93.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>-0.338262</td>\n",
              "      <td>1.119593</td>\n",
              "      <td>1.044367</td>\n",
              "      <td>-0.222187</td>\n",
              "      <td>0.499361</td>\n",
              "      <td>-0.246761</td>\n",
              "      <td>0.651583</td>\n",
              "      <td>0.069539</td>\n",
              "      <td>-0.736727</td>\n",
              "      <td>-0.366846</td>\n",
              "      <td>1.017614</td>\n",
              "      <td>0.836390</td>\n",
              "      <td>1.006844</td>\n",
              "      <td>-0.443523</td>\n",
              "      <td>0.150219</td>\n",
              "      <td>0.739453</td>\n",
              "      <td>-0.540980</td>\n",
              "      <td>0.476677</td>\n",
              "      <td>0.451773</td>\n",
              "      <td>0.203711</td>\n",
              "      <td>-0.246914</td>\n",
              "      <td>-0.633753</td>\n",
              "      <td>-0.120794</td>\n",
              "      <td>-0.385050</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>0.094199</td>\n",
              "      <td>0.246219</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>3.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0     0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1     0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2     1 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3     1 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4     2 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "5     2 -0.425966  0.960523  1.141109  ...  0.253844  0.081080    3.67      0\n",
              "6     4  1.229658  0.141004  0.045371  ...  0.034507  0.005168    4.99      0\n",
              "7     7 -0.644269  1.417964  1.074380  ... -1.206921 -1.085339   40.80      0\n",
              "8     7 -0.894286  0.286157 -0.113192  ...  0.011747  0.142404   93.20      0\n",
              "9     9 -0.338262  1.119593  1.044367  ...  0.246219  0.083076    3.68      0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bmX3sv_z_S_",
        "colab_type": "text"
      },
      "source": [
        "First 30 columns in this dataset are the input variables while the 31st column is the output i.e. if the transaction was a fraudulent transaction. \n",
        "\n",
        "So, we create 'X' as the array of the input variables while we keep the output label ( 0 or 1 ) in the 'y' array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOuT5dizrKuJ",
        "colab_type": "code",
        "outputId": "25a55d13-d887-4ebc-f881-ee26f7f4e19b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "X = dataframe.iloc[:,0:30].values\n",
        "y = dataframe.iloc[:,30:31].values\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5578, 30)\n",
            "(5578, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyoPWMR40YZN",
        "colab_type": "text"
      },
      "source": [
        "The input array has several columns with data ranging in their respective scales. To normalize the data we use StandardScaler module to normalize the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvn4PBinrcVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bpm2B9M90qIF",
        "colab_type": "text"
      },
      "source": [
        "After having normalized the input values, now it is time to split the data in training and validation datasets. Here, we have taken 30% as the validation dataset and 70% to the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9utwfJJTrkJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIBZsGsT02oU",
        "colab_type": "text"
      },
      "source": [
        "Now we are ready to create the neural network model. This is a binary classification type feedforward network. \n",
        "\n",
        "The input layer has 30 variables. We consider two dense layers of 64 neurons each before finally creating the output layer. We have considered 'RelU' activation for the dense layers while 'Sigmoid' for the output layer. This approach is as per the book 'Deep learning with python' book by Francois Chollet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaZtztuKrxOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "from keras import regularizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation = 'relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(16, activation = 'relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),loss=losses.binary_crossentropy,metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3vRlhOA1hEv",
        "colab_type": "text"
      },
      "source": [
        "Having created and compiled the neural model, now we train the dataset for 50 epochs and a batch size of 500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYxfYP7ZtdEh",
        "colab_type": "code",
        "outputId": "f02be92d-59fe-434d-ef88-6db76ab3d5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = 50, batch_size = 500, validation_data=(x_test, y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4462 samples, validate on 1116 samples\n",
            "Epoch 1/50\n",
            "4462/4462 [==============================] - 0s 77us/step - loss: 1.2830 - binary_accuracy: 0.1255 - val_loss: 0.9558 - val_binary_accuracy: 0.1828\n",
            "Epoch 2/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.9659 - binary_accuracy: 0.2981 - val_loss: 0.7525 - val_binary_accuracy: 0.4767\n",
            "Epoch 3/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.7781 - binary_accuracy: 0.4978 - val_loss: 0.6139 - val_binary_accuracy: 0.7760\n",
            "Epoch 4/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.6414 - binary_accuracy: 0.6981 - val_loss: 0.5083 - val_binary_accuracy: 0.9400\n",
            "Epoch 5/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.5337 - binary_accuracy: 0.8250 - val_loss: 0.4230 - val_binary_accuracy: 0.9848\n",
            "Epoch 6/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.4525 - binary_accuracy: 0.9050 - val_loss: 0.3540 - val_binary_accuracy: 0.9964\n",
            "Epoch 7/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.3810 - binary_accuracy: 0.9527 - val_loss: 0.2957 - val_binary_accuracy: 0.9982\n",
            "Epoch 8/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.3198 - binary_accuracy: 0.9787 - val_loss: 0.2469 - val_binary_accuracy: 0.9991\n",
            "Epoch 9/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.2758 - binary_accuracy: 0.9863 - val_loss: 0.2059 - val_binary_accuracy: 0.9991\n",
            "Epoch 10/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.2373 - binary_accuracy: 0.9913 - val_loss: 0.1724 - val_binary_accuracy: 0.9991\n",
            "Epoch 11/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.1980 - binary_accuracy: 0.9957 - val_loss: 0.1451 - val_binary_accuracy: 0.9991\n",
            "Epoch 12/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.1737 - binary_accuracy: 0.9966 - val_loss: 0.1235 - val_binary_accuracy: 0.9991\n",
            "Epoch 13/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.1483 - binary_accuracy: 0.9987 - val_loss: 0.1062 - val_binary_accuracy: 0.9991\n",
            "Epoch 14/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.1317 - binary_accuracy: 0.9982 - val_loss: 0.0932 - val_binary_accuracy: 0.9991\n",
            "Epoch 15/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.1133 - binary_accuracy: 0.9993 - val_loss: 0.0832 - val_binary_accuracy: 0.9991\n",
            "Epoch 16/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.1056 - binary_accuracy: 0.9989 - val_loss: 0.0756 - val_binary_accuracy: 0.9991\n",
            "Epoch 17/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0951 - binary_accuracy: 0.9993 - val_loss: 0.0699 - val_binary_accuracy: 0.9991\n",
            "Epoch 18/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0865 - binary_accuracy: 0.9993 - val_loss: 0.0657 - val_binary_accuracy: 0.9991\n",
            "Epoch 19/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0803 - binary_accuracy: 0.9996 - val_loss: 0.0622 - val_binary_accuracy: 0.9991\n",
            "Epoch 20/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0727 - binary_accuracy: 0.9996 - val_loss: 0.0592 - val_binary_accuracy: 0.9991\n",
            "Epoch 21/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0670 - binary_accuracy: 0.9996 - val_loss: 0.0567 - val_binary_accuracy: 0.9991\n",
            "Epoch 22/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0632 - binary_accuracy: 0.9996 - val_loss: 0.0544 - val_binary_accuracy: 0.9991\n",
            "Epoch 23/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0600 - binary_accuracy: 0.9996 - val_loss: 0.0523 - val_binary_accuracy: 0.9991\n",
            "Epoch 24/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0573 - binary_accuracy: 0.9996 - val_loss: 0.0503 - val_binary_accuracy: 0.9991\n",
            "Epoch 25/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0551 - binary_accuracy: 0.9996 - val_loss: 0.0484 - val_binary_accuracy: 0.9991\n",
            "Epoch 26/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0515 - binary_accuracy: 0.9996 - val_loss: 0.0466 - val_binary_accuracy: 0.9991\n",
            "Epoch 27/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0478 - binary_accuracy: 0.9996 - val_loss: 0.0448 - val_binary_accuracy: 0.9991\n",
            "Epoch 28/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.0459 - binary_accuracy: 0.9996 - val_loss: 0.0429 - val_binary_accuracy: 0.9991\n",
            "Epoch 29/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.0455 - binary_accuracy: 0.9996 - val_loss: 0.0413 - val_binary_accuracy: 0.9991\n",
            "Epoch 30/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0423 - binary_accuracy: 0.9996 - val_loss: 0.0396 - val_binary_accuracy: 0.9991\n",
            "Epoch 31/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.0384 - binary_accuracy: 0.9996 - val_loss: 0.0380 - val_binary_accuracy: 0.9991\n",
            "Epoch 32/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0369 - binary_accuracy: 0.9996 - val_loss: 0.0364 - val_binary_accuracy: 0.9991\n",
            "Epoch 33/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0358 - binary_accuracy: 0.9996 - val_loss: 0.0349 - val_binary_accuracy: 0.9991\n",
            "Epoch 34/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.0321 - binary_accuracy: 0.9996 - val_loss: 0.0337 - val_binary_accuracy: 0.9991\n",
            "Epoch 35/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0319 - binary_accuracy: 0.9996 - val_loss: 0.0324 - val_binary_accuracy: 0.9991\n",
            "Epoch 36/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0303 - binary_accuracy: 0.9996 - val_loss: 0.0311 - val_binary_accuracy: 0.9991\n",
            "Epoch 37/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.0290 - binary_accuracy: 0.9996 - val_loss: 0.0300 - val_binary_accuracy: 0.9991\n",
            "Epoch 38/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.0269 - binary_accuracy: 0.9996 - val_loss: 0.0291 - val_binary_accuracy: 0.9991\n",
            "Epoch 39/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0257 - binary_accuracy: 0.9996 - val_loss: 0.0280 - val_binary_accuracy: 0.9991\n",
            "Epoch 40/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0241 - binary_accuracy: 0.9996 - val_loss: 0.0270 - val_binary_accuracy: 0.9991\n",
            "Epoch 41/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.0236 - binary_accuracy: 0.9996 - val_loss: 0.0260 - val_binary_accuracy: 0.9991\n",
            "Epoch 42/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0230 - binary_accuracy: 0.9996 - val_loss: 0.0251 - val_binary_accuracy: 0.9991\n",
            "Epoch 43/50\n",
            "4462/4462 [==============================] - 0s 5us/step - loss: 0.0223 - binary_accuracy: 0.9996 - val_loss: 0.0243 - val_binary_accuracy: 0.9991\n",
            "Epoch 44/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0208 - binary_accuracy: 0.9996 - val_loss: 0.0236 - val_binary_accuracy: 0.9991\n",
            "Epoch 45/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0195 - binary_accuracy: 0.9996 - val_loss: 0.0231 - val_binary_accuracy: 0.9991\n",
            "Epoch 46/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0187 - binary_accuracy: 0.9996 - val_loss: 0.0224 - val_binary_accuracy: 0.9991\n",
            "Epoch 47/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0177 - binary_accuracy: 0.9996 - val_loss: 0.0217 - val_binary_accuracy: 0.9991\n",
            "Epoch 48/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0170 - binary_accuracy: 0.9996 - val_loss: 0.0212 - val_binary_accuracy: 0.9991\n",
            "Epoch 49/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0161 - binary_accuracy: 0.9996 - val_loss: 0.0206 - val_binary_accuracy: 0.9991\n",
            "Epoch 50/50\n",
            "4462/4462 [==============================] - 0s 6us/step - loss: 0.0157 - binary_accuracy: 0.9996 - val_loss: 0.0200 - val_binary_accuracy: 0.9991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9obM9j6U1zKH",
        "colab_type": "text"
      },
      "source": [
        "The output history has a history method which results in the dictionary of the output of the training step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mbRw4dKtLGc",
        "colab_type": "code",
        "outputId": "7e5dfadf-3b1a-490a-a5f6-4b55a13b8727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_binary_accuracy', 'loss', 'binary_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2lScFXj18_A",
        "colab_type": "text"
      },
      "source": [
        "Let us look at the training vs validation graphically. We use matplotlib for the purpose.\n",
        "\n",
        "As we can see here, the model converges well after only a few epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeYCl-jfvk8P",
        "colab_type": "code",
        "outputId": "bf11af73-f7f1-49d9-e8fb-1136ddf9f2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(history_dict['binary_accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAhA34yC3Dlq",
        "colab_type": "text"
      },
      "source": [
        "Similarly, we plot for training versus validation accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QenUUYfX2gPX",
        "colab_type": "code",
        "outputId": "cbe3bfb4-27af-450e-a84d-217fa182baed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "accuracy_values = history_dict['binary_accuracy']\n",
        "val_accuracy_values = history_dict['val_binary_accuracy']\n",
        "epochs = range(1, len(history_dict['binary_accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, accuracy_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy_values, 'b', label='Validation accuracy')\n",
        "\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35wDaWSv3nzB",
        "colab_type": "text"
      },
      "source": [
        "Evaluation of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOH649si3CuB",
        "colab_type": "code",
        "outputId": "df56ea6e-c34d-4204-ad2f-ffbfa9f6c9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "training_results = model.evaluate(x_train, y_train)\n",
        "print(\"Training results: {}\".format(training_results))\n",
        "test_results = model.evaluate(x_test, y_test)\n",
        "print(\"'Test results: {}\".format(test_results))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4462/4462 [==============================] - 0s 23us/step\n",
            "Training results: [0.012573235232845544, 0.9995517730712891]\n",
            "1116/1116 [==============================] - 0s 26us/step\n",
            "'Test results: [0.02000831012150079, 0.9991039633750916]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuEyeZl53kRU",
        "colab_type": "text"
      },
      "source": [
        "Predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j51j8qt3aGs",
        "colab_type": "code",
        "outputId": "f7476bf2-dd44-4829-8a23-97769422f277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_predictions = model.predict(x_test)\n",
        "\n",
        "deviation = 0\n",
        "for i in range(len(x_test)):\n",
        "  y_actual = float(y_test[i])\n",
        "  y_predicted = float(y_predictions[i])\n",
        "  diff = y_actual - y_predicted\n",
        "  deviation += diff\n",
        "\n",
        "print(deviation)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7392819463581644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yU5lCagA3iM",
        "colab_type": "code",
        "outputId": "581cff68-1f08-4c99-9220-48afde759189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "y_actual = [int(i) for i in y_test]\n",
        "y_predicted = [int(i) for i in y_predictions]\n",
        "\n",
        "error_count = 0\n",
        "\n",
        "for i in range(len(y_actual)):\n",
        "  if y_actual[i] == y_predicted[i]:\n",
        "    continue\n",
        "  else:\n",
        "    error_count += 1\n",
        "\n",
        "error_count_percent = ((error_count * 100) / len(y_actual))\n",
        "success_count_percent = (len(y_actual) - error_count)*100 / len(y_actual)\n",
        "\n",
        "print(\"Number of error counts is : {}\". format(error_count))\n",
        "print(\"Total number of data rows is : {}\". format(len(y_actual)))\n",
        "print(\"Error count percentage is : {}\".format(error_count_percent))\n",
        "print(\"Success count percentage is : {}\".format(success_count_percent))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of error counts is : 1\n",
            "Total number of data rows is : 1116\n",
            "Error count percentage is : 0.08960573476702509\n",
            "Success count percentage is : 99.91039426523298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT4xmphfDFRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}